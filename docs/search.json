[
  {
    "objectID": "ST558 HW5 Quarto Doc.html",
    "href": "ST558 HW5 Quarto Doc.html",
    "title": "ST558 HW5 Quarto Doc",
    "section": "",
    "text": "#ST558 HW4: Liam Flaherty"
  },
  {
    "objectID": "ST558 HW5 Quarto Doc.html#task-1-conceptual-questions",
    "href": "ST558 HW5 Quarto Doc.html#task-1-conceptual-questions",
    "title": "ST558 HW5 Quarto Doc",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nTask 1, Question 1\n\nWhat is the purpose of using cross-validation when fitting a random forest model?\n\n\nIn general, using cross-validation allows us to prevent overfitting when we don’t have sufficient data to split into training and test data.\n\n\n\nTask 1, Question 2\n\nDescribe the bagged tree algorithm.\n\n\nThe bagged tree algorithm essentially samples with replacement from itself, then builds trees on each sample subset.\n\n\n\nTask 1, Question 3\n\nWhat is meant by a general linear model?\n\n\nA general linear model is one that has a continuous response variable and (potentially) continuous and categorical predictors. This stands in contrast to generalized linear models, which allow for responses that are non-normal.\n\n\n\nTask 1, Question 4\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to differently as compared to when it is not included in the model?\n\n\nThe interaction term in the model is used when the two variables have different effects when considered together. For example, may asprin has an effect on heart rate, and alchohol has an effect on heart rate, but the precence of both alchohol and asprin generate different effects.\n\n\n\nTask 1, Question 5\n\nWhy do we split our data into a training and test set?\n\n\nWe split the data into training and tests sets to evaluate our models and prevent overfitting. Whenever we add terms, our correlation can only improve. But more complicated models may suffer from overfitting. When comparing models, we generally select the model which does “best” (by way of a measurment such as MSE) on the test data."
  },
  {
    "objectID": "ST558 HW5 Quarto Doc.html#task-2-fitting-models",
    "href": "ST558 HW5 Quarto Doc.html#task-2-fitting-models",
    "title": "ST558 HW5 Quarto Doc",
    "section": "Task 2: Fitting Models",
    "text": "Task 2: Fitting Models\nWe are given some data on heart disease from https://www4.stat.ncsu.edu/~online/datasets/heart.csv. We first download the data locally, then store it as an R object as usual.\n\nlibrary(tidyverse)\n\nWarning: package 'lubridate' was built under R version 4.4.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nheart=read_csv(\"heart.csv\", show_col_types = FALSE)\nheart                             #get a glimpse of the data#\n\n# A tibble: 918 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\n\nTask 2, EDA Part 1\nWe want to get a quick glimpse of our data. We can see that there are no missing values, but there are some irregularities. For example, in our summary, we see that certain people have a cholesterol of zero, a resting bloop pressure of zero, and a max heart rate of just 60bpm (while 60 would be a fine resting heart rate, a maximum heart rate that low suggests death).\n\nsum(is.na(heart))                 #no missing values#\n\n[1] 0\n\nsummary(heart)                    #normal summaries#\n\n      Age            Sex            ChestPainType        RestingBP    \n Min.   :28.00   Length:918         Length:918         Min.   :  0.0  \n 1st Qu.:47.00   Class :character   Class :character   1st Qu.:120.0  \n Median :54.00   Mode  :character   Mode  :character   Median :130.0  \n Mean   :53.51                                         Mean   :132.4  \n 3rd Qu.:60.00                                         3rd Qu.:140.0  \n Max.   :77.00                                         Max.   :200.0  \n  Cholesterol      FastingBS       RestingECG            MaxHR      \n Min.   :  0.0   Min.   :0.0000   Length:918         Min.   : 60.0  \n 1st Qu.:173.2   1st Qu.:0.0000   Class :character   1st Qu.:120.0  \n Median :223.0   Median :0.0000   Mode  :character   Median :138.0  \n Mean   :198.8   Mean   :0.2331                      Mean   :136.8  \n 3rd Qu.:267.0   3rd Qu.:0.0000                      3rd Qu.:156.0  \n Max.   :603.0   Max.   :1.0000                      Max.   :202.0  \n ExerciseAngina        Oldpeak          ST_Slope          HeartDisease   \n Length:918         Min.   :-2.6000   Length:918         Min.   :0.0000  \n Class :character   1st Qu.: 0.0000   Class :character   1st Qu.:0.0000  \n Mode  :character   Median : 0.6000   Mode  :character   Median :1.0000  \n                    Mean   : 0.8874                      Mean   :0.5534  \n                    3rd Qu.: 1.5000                      3rd Qu.:1.0000  \n                    Max.   : 6.2000                      Max.   :1.0000  \n\n\nThere are a couple choices when dealing with such implausible data. One is to insert “dummy data”, taking the average of all other values of the same predictor (essentially trading off information on the covariance among the predictors in an effort to preserve other variables for the observation which might be useful). A simpler way would be to delete the observations entirely. We should be careful though. While a maximum heart rate below 100 seems implausible, we should keep in mind that the data is based around heart failure. Indeed, when we check the data, we see that nearly 8% of our observations have a max heart rates under 100– probably too much to be errors. Similarly, we see over 20% of our data have a cholesterol of zero. Since the data has been collected from multiple sources, it might be the case that certain sources have not included cholesterol in their measurements. It seems extreme to drop the observations entirely, as the other variables for the subject might be legitimate. For now, we will leave the dataset alone, and tend to the heart rate and cholesterol questions when we get a clearer sense of what our model might look like.\n\nsum(heart$MaxHR&lt;100)                 #71#\n\n[1] 71\n\nsum(heart$Cholesterol==0)            #172#\n\n[1] 172\n\nheart[which(heart$RestingBP==0),]\n\n# A tibble: 1 × 12\n    Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n1    55 M     NAP                   0           0         0 Normal       155\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\n\n\nTask 2, EDA Part 2\nWe would like to make some minor alterations to our dataset. First, we transform the binary response (the presence of heart disease) from numeric to factor using tivdyverse’s mutate(). Next, we remove the ST_Slope and old numeric heart disease variables from our tibble.\n\nheart=heart|&gt;\n  mutate(HeartDisease=as.factor(HeartDisease)) |&gt;\n  select(-ST_Slope)\n\n\n\nTask 2, EDA Part 3\nWe are going to be performing a k-Nearest Neighbors analysis to predict whether or not someone has heart disease. In general, we want all numeric predictors for such an analysis. Luckily, the caret package offers a way to transform our data.\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.4.1\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\ndummies=dummyVars(~ Sex + ChestPainType + RestingECG + ExerciseAngina,\n                 data=heart)\ndummydf=predict(dummies, newdata=heart)\nheart=as_tibble(cbind(heart,dummydf))\n\nheart\n\n# A tibble: 918 × 22\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 14 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, HeartDisease &lt;fct&gt;,\n#   SexF &lt;dbl&gt;, SexM &lt;dbl&gt;, ChestPainTypeASY &lt;dbl&gt;, ChestPainTypeATA &lt;dbl&gt;,\n#   ChestPainTypeNAP &lt;dbl&gt;, ChestPainTypeTA &lt;dbl&gt;, RestingECGLVH &lt;dbl&gt;,\n#   RestingECGNormal &lt;dbl&gt;, RestingECGST &lt;dbl&gt;, ExerciseAnginaN &lt;dbl&gt;,\n#   ExerciseAnginaY &lt;dbl&gt;\n\n\n\n\nTask 2, Split Data\nWe’d now like to split our data into a training and test set. We can do this with normal BaseR functions, sample()ing without replacement 80% of the rows of our full tibble for our training set, and then putting the remaining rows in our test set with setdiff(). Note that in both our training and test sets, we only select the numeric columns using select_if() from the tidyverse.\n\nset.seed(558)   #to make reproducible#\ntraining=sample(1:nrow(heart), size=nrow(heart)*.8, replace=FALSE)\ntest=setdiff(1:nrow(heart), training)\n\nheart_training=heart[training,] |&gt; select_if(function(x) !is.character(x))\nheart_test=heart[test,] |&gt; select_if(function(x) !is.character(x))\n\n\n\nTask 2, kNN\nWith our split data in hand, we can now train our model. We first center and scale our predictors (with the preProcess arguement to train() from the caret package). We want to test different choices of \\(k\\), so create a data frame of forty rows (one for each value of \\(k\\) that we are testing) with the tuneGrid argument. These forty values of \\(k\\) are tested with cross-validation. We use 10-fold cross-validation (i.e. 10 disjoint sets, with nine acting as a predictor and the final as a test set, for each of the 10 sets in turn), repeating the process three times for each \\(k\\) in order to make our prediction more stable (this is done with the trControl arguement). The below shows that our best choice of \\(k\\), when all numeric predictors are included, is a \\(k\\) value of 19.\n\nmyknn=train(HeartDisease ~.,\n            data=heart_training,\n            method=\"knn\",\n            trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3),\n            preProcess=c(\"center\", \"scale\"),\n            tuneGrid=data.frame(k=1:40)\n            )\nmyknn\n\nk-Nearest Neighbors \n\n734 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 661, 660, 660, 662, 661, 660, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   1  0.7671332  0.5330004\n   2  0.7652699  0.5288929\n   3  0.7970801  0.5937635\n   4  0.8034797  0.6059701\n   5  0.8206403  0.6393574\n   6  0.8092920  0.6174906\n   7  0.8165112  0.6314335\n   8  0.8156041  0.6292951\n   9  0.8164989  0.6312129\n  10  0.8069964  0.6119828\n  11  0.8142154  0.6266282\n  12  0.8083224  0.6147446\n  13  0.8069462  0.6121794\n  14  0.8110499  0.6207160\n  15  0.8142029  0.6270861\n  16  0.8151100  0.6289900\n  17  0.8196515  0.6380220\n  18  0.8196827  0.6380709\n  19  0.8224041  0.6435861\n  20  0.8219723  0.6429193\n  21  0.8210839  0.6409391\n  22  0.8205781  0.6401042\n  23  0.8205839  0.6400217\n  24  0.8165110  0.6320088\n  25  0.8169431  0.6327699\n  26  0.8129016  0.6250645\n  27  0.8142404  0.6271753\n  28  0.8106247  0.6198193\n  29  0.8115501  0.6217575\n  30  0.8060891  0.6102696\n  31  0.8042563  0.6067162\n  32  0.8061265  0.6106504\n  33  0.8034051  0.6049348\n  34  0.8043120  0.6065031\n  35  0.8088537  0.6153281\n  36  0.8097546  0.6172516\n  37  0.8115628  0.6206786\n  38  0.8129328  0.6230822\n  39  0.8097234  0.6165540\n  40  0.8124698  0.6219957\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 19.\n\n\nWe can check the accuracy of our knn against our test set. We use the confusionMatrix() function from the caret library to see that our overall accuracy is about 82%, with balanced accuracy for both people who actually have heart disease and actually don’t have heart disease (about 45.8% of the data in our test set actually did not have heart disease, which we correctly predicted about 82.7% of the time, while the remaining 54.2% of our test set actually did have heart disease, which we correctly predicted about 81.5% if the time).\n\nconfusionMatrix(myknn, newdata=heart_test)\n\nCross-Validated (10 fold, repeated 3 times) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction    0    1\n         0 38.0  9.9\n         1  7.8 44.3\n                            \n Accuracy (average) : 0.8224\n\n\n\n\nTask 2, Logistic Regression\nLet’s now try some different types of analysis. Since our response is binary (you either have heart disease or you don’t) it makes sense to try out a logistic regression. We try a few different models below. We elect to chose the model with the lowest AIC, which happends to be our full model.\n\nlog_model_full=train(HeartDisease ~., \n                data=heart_training,\n                method=\"glm\",\n                family=\"binomial\",\n                preProcess=c(\"center\", \"scale\"),\n                trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3))\n\nlog_model_reduced=train(HeartDisease ~ Cholesterol + FastingBS + ExerciseAnginaN + MaxHR + Oldpeak + SexF, \n                data=heart_training,\n                method=\"glm\",\n                family=\"binomial\",\n                preProcess=c(\"center\", \"scale\"),\n                trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3))\n\n\nlog_model_reduced_min=train(HeartDisease ~ Cholesterol + FastingBS + MaxHR, \n                data=heart_training,\n                method=\"glm\",\n                family=\"binomial\",\n                preProcess=c(\"center\", \"scale\"),\n                trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3))\n\ndf=data.frame(model=c(\"full\", \"reduced\", \"minimal\"), \n           AIC=c(summary(log_model_full)$aic, \n                 summary(log_model_reduced)$aic, \n                 summary(log_model_reduced_min)$aic))\n\ndf\n\n    model      AIC\n1    full 601.9880\n2 reduced 654.9311\n3 minimal 826.2931\n\nsummary(log_model_full)\n\n\nCall:\nNULL\n\nCoefficients: (4 not defined because of singularities)\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       0.31044    0.11135   2.788 0.005303 ** \nAge               0.22031    0.12713   1.733 0.083101 .  \nRestingBP        -0.01470    0.11115  -0.132 0.894789    \nCholesterol      -0.33145    0.12327  -2.689 0.007170 ** \nFastingBS         0.44716    0.11760   3.802 0.000143 ***\nMaxHR            -0.41008    0.12746  -3.217 0.001295 ** \nOldpeak           0.62953    0.13229   4.759 1.95e-06 ***\nSexF             -0.44572    0.11098  -4.016 5.91e-05 ***\nSexM                   NA         NA      NA       NA    \nChestPainTypeASY  0.65348    0.21544   3.033 0.002420 ** \nChestPainTypeATA -0.29793    0.19330  -1.541 0.123249    \nChestPainTypeNAP -0.06822    0.18864  -0.362 0.717603    \nChestPainTypeTA        NA         NA      NA       NA    \nRestingECGLVH     0.08382    0.14601   0.574 0.565909    \nRestingECGNormal  0.10322    0.14425   0.716 0.474245    \nRestingECGST           NA         NA      NA       NA    \nExerciseAnginaN  -0.55696    0.12302  -4.527 5.98e-06 ***\nExerciseAnginaY        NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1012.30  on 733  degrees of freedom\nResidual deviance:  573.99  on 720  degrees of freedom\nAIC: 601.99\n\nNumber of Fisher Scoring iterations: 5\n\n\nWe would like to test how well our selected model does on our test data. We elect to use the same confusionMatrix() function we tried with \\(k\\)-nn, and see that the model correctly predicts about 82% of the time. This is similar to the result we got from \\(k\\)-nn.\n\nconfusionMatrix(log_model_full, newdata=heart_test)\n\nCross-Validated (10 fold, repeated 3 times) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction    0    1\n         0 36.4  8.6\n         1  9.4 45.6\n                            \n Accuracy (average) : 0.8206\n\n\n\n\nTask 2, Tree Models\nAnother type of analysis that might be of interest are classification trees. We will first try a single tree, then use ensemble methods like random forests and boosted trees. We elect to do a model with our full parameter set.\n\nmytree=train(HeartDisease~., \n             data=heart_training,\n             method=\"rpart\",\n             preProcess=c(\"center\", \"scale\"),\n             trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3),\n             tuneGrid=data.frame(cp=seq(from=0, to=0.1, by=0.001))\n             )\nmytree\n\nCART \n\n734 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 660, 660, 660, 661, 660, 661, ... \nResampling results across tuning parameters:\n\n  cp     Accuracy   Kappa    \n  0.000  0.7606668  0.5168861\n  0.001  0.7620367  0.5198000\n  0.002  0.7688682  0.5337082\n  0.003  0.7702132  0.5365661\n  0.004  0.7693308  0.5346807\n  0.005  0.7766369  0.5498980\n  0.006  0.7784637  0.5537600\n  0.007  0.7770939  0.5510891\n  0.008  0.7775443  0.5520221\n  0.009  0.7784637  0.5539416\n  0.010  0.7785320  0.5549792\n  0.011  0.7785320  0.5549792\n  0.012  0.7789824  0.5561523\n  0.013  0.7771559  0.5520898\n  0.014  0.7761928  0.5495372\n  0.015  0.7761681  0.5483193\n  0.016  0.7766122  0.5477721\n  0.017  0.7797714  0.5536222\n  0.018  0.7852267  0.5631444\n  0.019  0.7834187  0.5594782\n  0.020  0.7834002  0.5598594\n  0.021  0.7834002  0.5598594\n  0.022  0.7811356  0.5554273\n  0.023  0.7811356  0.5554273\n  0.024  0.7793588  0.5517971\n  0.025  0.7793588  0.5517971\n  0.026  0.7793588  0.5517971\n  0.027  0.7780075  0.5489716\n  0.028  0.7780075  0.5489716\n  0.029  0.7780075  0.5489716\n  0.030  0.7734471  0.5393351\n  0.031  0.7734471  0.5393351\n  0.032  0.7734471  0.5393351\n  0.033  0.7734471  0.5393351\n  0.034  0.7666406  0.5252494\n  0.035  0.7666406  0.5253100\n  0.036  0.7666406  0.5253100\n  0.037  0.7643258  0.5209078\n  0.038  0.7643258  0.5209078\n  0.039  0.7643258  0.5209078\n  0.040  0.7652390  0.5233722\n  0.041  0.7652390  0.5233722\n  0.042  0.7652390  0.5233722\n  0.043  0.7652390  0.5233722\n  0.044  0.7611665  0.5160426\n  0.045  0.7611665  0.5160426\n  0.046  0.7611665  0.5160426\n  0.047  0.7584391  0.5110840\n  0.048  0.7584391  0.5110840\n  0.049  0.7584391  0.5110840\n  0.050  0.7575382  0.5097072\n  0.051  0.7575382  0.5097072\n  0.052  0.7575382  0.5097072\n  0.053  0.7575382  0.5100637\n  0.054  0.7575382  0.5100637\n  0.055  0.7575382  0.5100637\n  0.056  0.7575382  0.5100637\n  0.057  0.7580137  0.5115952\n  0.058  0.7580137  0.5115952\n  0.059  0.7580137  0.5115952\n  0.060  0.7607287  0.5180293\n  0.061  0.7607287  0.5180293\n  0.062  0.7607287  0.5180293\n  0.063  0.7625490  0.5219749\n  0.064  0.7625490  0.5219749\n  0.065  0.7625490  0.5219749\n  0.066  0.7625490  0.5219749\n  0.067  0.7643508  0.5258517\n  0.068  0.7643508  0.5258517\n  0.069  0.7643508  0.5258517\n  0.070  0.7643508  0.5258517\n  0.071  0.7643508  0.5258517\n  0.072  0.7643508  0.5258517\n  0.073  0.7643508  0.5258517\n  0.074  0.7643508  0.5258517\n  0.075  0.7643508  0.5258517\n  0.076  0.7643508  0.5258517\n  0.077  0.7643508  0.5258517\n  0.078  0.7643508  0.5258517\n  0.079  0.7643508  0.5258517\n  0.080  0.7643508  0.5258517\n  0.081  0.7643508  0.5258517\n  0.082  0.7643508  0.5258517\n  0.083  0.7643508  0.5258517\n  0.084  0.7643508  0.5258517\n  0.085  0.7643508  0.5258517\n  0.086  0.7643508  0.5258517\n  0.087  0.7643508  0.5258517\n  0.088  0.7643508  0.5258517\n  0.089  0.7643508  0.5258517\n  0.090  0.7643508  0.5258517\n  0.091  0.7643508  0.5258517\n  0.092  0.7643508  0.5258517\n  0.093  0.7643508  0.5258517\n  0.094  0.7643508  0.5258517\n  0.095  0.7643508  0.5258517\n  0.096  0.7643508  0.5258517\n  0.097  0.7643508  0.5258517\n  0.098  0.7643508  0.5258517\n  0.099  0.7643508  0.5258517\n  0.100  0.7643508  0.5258517\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.018.\n\n\nWe see the accuracy is slightly worse than our \\(k\\)-nn and logistic regression models.\n\nconfusionMatrix(mytree, newdata=heart_test)\n\nCross-Validated (10 fold, repeated 3 times) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction    0    1\n         0 32.2  7.9\n         1 13.6 46.4\n                            \n Accuracy (average) : 0.7852\n\n\nMaybe a random forest will perform better. The only alteration we need from the above is changing our method argument from rpart to rf, and our tuneGrid argument to mtry, ranging from 1 to our number of parameters.\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.4.1\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nmyrandomforest=train(HeartDisease~., \n             data=heart_training,\n             method=\"rf\",\n             preProcess=c(\"center\", \"scale\"),\n             trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3),\n             tuneGrid=data.frame(mtry=1:(ncol(heart_training)-1))\n             )\nmyrandomforest\n\nRandom Forest \n\n734 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 662, 660, 661, 660, 661, 660, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n   1    0.8120951  0.6208480\n   2    0.8207349  0.6382425\n   3    0.8260965  0.6493040\n   4    0.8238255  0.6448445\n   5    0.8206786  0.6389463\n   6    0.8188397  0.6349697\n   7    0.8184013  0.6344306\n   8    0.8220923  0.6414420\n   9    0.8193085  0.6357903\n  10    0.8188456  0.6349851\n  11    0.8170374  0.6315265\n  12    0.8156674  0.6289547\n  13    0.8174817  0.6322295\n  14    0.8138594  0.6249229\n  15    0.8147668  0.6267496\n  16    0.8120518  0.6211150\n  17    0.8134155  0.6241238\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 3.\n\n\nThe accuracy with our random forest improves to about the level of our logistic regression and our \\(k\\)-nn algorithm.\n\nconfusionMatrix(myrandomforest, newdata=heart_test)\n\nCross-Validated (10 fold, repeated 3 times) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction    0    1\n         0 36.7  8.4\n         1  9.0 45.9\n                            \n Accuracy (average) : 0.8261\n\n\nMaybe boosting our results will improve it even further. To do so we change our method to gbm and tweak the parameters to our tuneGrid in line with the instructions given.\n\nlibrary(gbm)\n\nWarning: package 'gbm' was built under R version 4.4.1\n\n\nLoaded gbm 2.2.2\n\n\nThis version of gbm is no longer under development. Consider transitioning to gbm3, https://github.com/gbm-developers/gbm3\n\nmyboosted=train(HeartDisease~., \n             data=heart_training,\n             method=\"gbm\",\n             preProcess=c(\"center\", \"scale\"),\n             trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3),\n             tuneGrid=expand.grid(n.trees=c(25,50,100,200),\n                                  interaction.depth=1:3,\n                                  shrinkage=0.1,\n                                  n.minobsinnode=10),\n             verbose=FALSE\n             )\nmyboosted\n\nStochastic Gradient Boosting \n\n734 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 660, 660, 661, 660, 661, 661, ... \nResampling results across tuning parameters:\n\n  interaction.depth  n.trees  Accuracy   Kappa    \n  1                   25      0.8056044  0.6074075\n  1                   50      0.8137744  0.6242713\n  1                  100      0.8174275  0.6325690\n  1                  200      0.8265548  0.6507694\n  2                   25      0.8097022  0.6153279\n  2                   50      0.8187856  0.6344475\n  2                  100      0.8296889  0.6563219\n  2                  200      0.8288312  0.6545919\n  3                   25      0.8183284  0.6333168\n  3                   50      0.8260978  0.6493136\n  3                  100      0.8292635  0.6555039\n  3                  200      0.8251723  0.6476082\n\nTuning parameter 'shrinkage' was held constant at a value of 0.1\n\nTuning parameter 'n.minobsinnode' was held constant at a value of 10\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were n.trees = 100, interaction.depth =\n 2, shrinkage = 0.1 and n.minobsinnode = 10.\n\n\nIndeed, we see it does offer a slight improvement; it is our best model!\n\nconfusionMatrix(myboosted, newdata=heart_test)\n\nCross-Validated (10 fold, repeated 3 times) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction    0    1\n         0 37.0  8.2\n         1  8.8 46.0\n                            \n Accuracy (average) : 0.8297"
  }
]