[
  {
    "objectID": "ST558 HW5 Quarto Doc.html",
    "href": "ST558 HW5 Quarto Doc.html",
    "title": "ST558 HW5 Quarto Doc",
    "section": "",
    "text": "#ST558 HW4: Liam Flaherty"
  },
  {
    "objectID": "ST558 HW5 Quarto Doc.html#task-1-conceptual-questions",
    "href": "ST558 HW5 Quarto Doc.html#task-1-conceptual-questions",
    "title": "ST558 HW5 Quarto Doc",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nTask 1, Question 1\n\nWhat is the purpose of using cross-validation when fitting a random forest model?\n\n\nIn general, using cross-validation allows us to prevent overfitting when we don’t have sufficient data to split into training and test data.\n\n\n\nTask 1, Question 2\n\nDescribe the bagged tree algorithm.\n\n\nThe bagged tree algorithm essentially samples with replacement from itself, then builds trees on each sample subset.\n\n\n\nTask 1, Question 3\n\nWhat is meant by a general linear model?\n\n\nA general linear model is one that has a continuous response variable and (potentially) continuous and categorical predictors. This stands in contrast to generalized linear models, which allow for responses that are non-normal.\n\n\n\nTask 1, Question 4\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to differently as compared to when it is not included in the model?\n\n\nThe interaction term in the model is used when the two variables have different effects when considered together. For example, may asprin has an effect on heart rate, and alchohol has an effect on heart rate, but the precence of both alchohol and asprin generate different effects.\n\n\n\nTask 1, Question 5\n\nWhy do we split our data into a training and test set?\n\n\nWe split the data into training and tests sets to evaluate our models and prevent overfitting. Whenever we add terms, our correlation can only improve. But more complicated models may suffer from overfitting. When comparing models, we generally select the model which does “best” (by way of a measurment such as MSE) on the test data."
  },
  {
    "objectID": "ST558 HW5 Quarto Doc.html#task-2-fitting-models",
    "href": "ST558 HW5 Quarto Doc.html#task-2-fitting-models",
    "title": "ST558 HW5 Quarto Doc",
    "section": "Task 2: Fitting Models",
    "text": "Task 2: Fitting Models\nWe are given some data on heart disease from https://www4.stat.ncsu.edu/~online/datasets/heart.csv. We first download the data locally, then store it as an R object as usual.\n\nlibrary(tidyverse)\n\nWarning: package 'lubridate' was built under R version 4.4.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nheart=read_csv(\"heart.csv\", show_col_types = FALSE)\nheart                             #get a glimpse of the data#\n\n# A tibble: 918 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\n\nTask 2, EDA Part 1\nWe want to get a quick glimpse of our data. We can see that there are no missing values, but there are some irregularities. For example, in our summary, we see that certain people have a cholesterol of zero, a resting bloop pressure of zero, and a max heart rate of just 60bpm (while 60 would be a fine resting heart rate, a maximum heart rate that low suggests death).\n\nsum(is.na(heart))                 #no missing values#\n\n[1] 0\n\nsummary(heart)                    #normal summaries#\n\n      Age            Sex            ChestPainType        RestingBP    \n Min.   :28.00   Length:918         Length:918         Min.   :  0.0  \n 1st Qu.:47.00   Class :character   Class :character   1st Qu.:120.0  \n Median :54.00   Mode  :character   Mode  :character   Median :130.0  \n Mean   :53.51                                         Mean   :132.4  \n 3rd Qu.:60.00                                         3rd Qu.:140.0  \n Max.   :77.00                                         Max.   :200.0  \n  Cholesterol      FastingBS       RestingECG            MaxHR      \n Min.   :  0.0   Min.   :0.0000   Length:918         Min.   : 60.0  \n 1st Qu.:173.2   1st Qu.:0.0000   Class :character   1st Qu.:120.0  \n Median :223.0   Median :0.0000   Mode  :character   Median :138.0  \n Mean   :198.8   Mean   :0.2331                      Mean   :136.8  \n 3rd Qu.:267.0   3rd Qu.:0.0000                      3rd Qu.:156.0  \n Max.   :603.0   Max.   :1.0000                      Max.   :202.0  \n ExerciseAngina        Oldpeak          ST_Slope          HeartDisease   \n Length:918         Min.   :-2.6000   Length:918         Min.   :0.0000  \n Class :character   1st Qu.: 0.0000   Class :character   1st Qu.:0.0000  \n Mode  :character   Median : 0.6000   Mode  :character   Median :1.0000  \n                    Mean   : 0.8874                      Mean   :0.5534  \n                    3rd Qu.: 1.5000                      3rd Qu.:1.0000  \n                    Max.   : 6.2000                      Max.   :1.0000  \n\n\nThere are a couple choices when dealing with such implausible data. One is to insert “dummy data”, taking the average of all other values of the same predictor (essentially trading off information on the covariance among the predictors in an effort to preserve other variables for the observation which might be useful). A simpler way would be to delete the observations entirely. We should be careful though. While a maximum heart rate below 100 seems implausible, we should keep in mind that the data is based around heart failure. Indeed, when we check the data, we see that nearly 8% of our observations have a max heart rates under 100– probably too much to be errors. Similarly, we see over 20% of our data have a cholesterol of zero. Since the data has been collected from multiple sources, it might be the case that certain sources have not included cholesterol in their measurements. It seems extreme to drop the observations entirely, as the other variables for the subject might be legitimate. For now, we will leave the dataset alone, and tend to the heart rate and cholesterol questions when we get a clearer sense of what our model might look like.\n\nsum(heart$MaxHR&lt;100)                 #71#\n\n[1] 71\n\nsum(heart$Cholesterol==0)            #172#\n\n[1] 172\n\nheart[which(heart$RestingBP==0),]\n\n# A tibble: 1 × 12\n    Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n1    55 M     NAP                   0           0         0 Normal       155\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\n\n\nTask 2, EDA Part 2\nWe would like to make some minor alterations to our dataset. First, we transform the binary response (the presence of heart disease) from numeric to factor using tivdyverse’s mutate(). Next, we remove the ST_Slope and old numeric heart disease variables from our tibble.\n\nheart=heart|&gt;\n  mutate(HeartDisease=as.factor(HeartDisease)) |&gt;\n  select(-ST_Slope)\n\n\n\nTask 2, EDA Part 3\nWe are going to be performing a k-Nearest Neighbors analysis to predict whether or not someone has heart disease. In general, we want all numeric predictors for such an analysis. Luckily, the caret package offers a way to transform our data.\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.4.1\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\ndummies=dummyVars(~ Sex + ChestPainType + RestingECG + ExerciseAngina,\n                 data=heart)\ndummydf=predict(dummies, newdata=heart)\nheart=as_tibble(cbind(heart,dummydf))\n\nheart\n\n# A tibble: 918 × 22\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 14 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, HeartDisease &lt;fct&gt;,\n#   SexF &lt;dbl&gt;, SexM &lt;dbl&gt;, ChestPainTypeASY &lt;dbl&gt;, ChestPainTypeATA &lt;dbl&gt;,\n#   ChestPainTypeNAP &lt;dbl&gt;, ChestPainTypeTA &lt;dbl&gt;, RestingECGLVH &lt;dbl&gt;,\n#   RestingECGNormal &lt;dbl&gt;, RestingECGST &lt;dbl&gt;, ExerciseAnginaN &lt;dbl&gt;,\n#   ExerciseAnginaY &lt;dbl&gt;\n\n\n\n\nTask 2, Split Data\nWe’d now like to split our data into a training and test set. We can do this with normal BaseR functions, sample()ing without replacement 80% of the rows of our full tibble for our training set, and then putting the remaining rows in our test set with setdiff().\n\nset.seed(558)   #to make reproducible#\ntraining=sample(1:nrow(heart), size=nrow(heart)*.8, replace=FALSE)\ntest=setdiff(1:nrow(heart), training)\n\nheart_training=heart[training,] |&gt; select_if(function(x) !is.character(x))\nheart_test=heart[test,] |&gt; select_if(function(x) !is.character(x))\n\n\n\nTask 2, kNN\nWe now run our K-nn algorithm.\n\nmyknn=train(HeartDisease ~.,\n            data=heart_training,\n            method=\"knn\",\n            trControl=trainControl(method=\"repeatedcv\", number=10, repeats=3),\n            preProcess=c(\"center\", \"scale\"),\n            tuneGrid=data.frame(k=1:40)\n            )\nmyknn\n\nk-Nearest Neighbors \n\n734 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 661, 660, 660, 662, 661, 660, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   1  0.7671332  0.5330004\n   2  0.7652699  0.5288929\n   3  0.7970801  0.5937635\n   4  0.8034797  0.6059701\n   5  0.8206403  0.6393574\n   6  0.8092920  0.6174906\n   7  0.8165112  0.6314335\n   8  0.8156041  0.6292951\n   9  0.8164989  0.6312129\n  10  0.8069964  0.6119828\n  11  0.8142154  0.6266282\n  12  0.8083224  0.6147446\n  13  0.8069462  0.6121794\n  14  0.8110499  0.6207160\n  15  0.8142029  0.6270861\n  16  0.8151100  0.6289900\n  17  0.8196515  0.6380220\n  18  0.8196827  0.6380709\n  19  0.8224041  0.6435861\n  20  0.8219723  0.6429193\n  21  0.8210839  0.6409391\n  22  0.8205781  0.6401042\n  23  0.8205839  0.6400217\n  24  0.8165110  0.6320088\n  25  0.8169431  0.6327699\n  26  0.8129016  0.6250645\n  27  0.8142404  0.6271753\n  28  0.8106247  0.6198193\n  29  0.8115501  0.6217575\n  30  0.8060891  0.6102696\n  31  0.8042563  0.6067162\n  32  0.8061265  0.6106504\n  33  0.8034051  0.6049348\n  34  0.8043120  0.6065031\n  35  0.8088537  0.6153281\n  36  0.8097546  0.6172516\n  37  0.8115628  0.6206786\n  38  0.8129328  0.6230822\n  39  0.8097234  0.6165540\n  40  0.8124698  0.6219957\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 19.\n\n\nWe can check the accuracy of our knn against our test set. We use the confusionMatrix() function from the caret library to see that our overall accuracy is about 82%, with balanced accuracy for both people who actually have heart disease and actually don’t have heart disease (about 45.8% of the data in our test set actually did not have heart disease, which we correctly predicted about 82.7% of the time, while the remaining 54.2% of our test set actually did have heart disease, which we correctly predicted about 81.5% if the time).\n\nconfusionMatrix(myknn, newdata=heart_test)\n\nCross-Validated (10 fold, repeated 3 times) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction    0    1\n         0 38.0  9.9\n         1  7.8 44.3\n                            \n Accuracy (average) : 0.8224\n\n\n\n\nTask 2, Logistic Regression\n\n\nTask 2, Tree Models"
  }
]